{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97d9d54",
   "metadata": {},
   "source": [
    "# Python Riva API\n",
    "\n",
    "This tutorial demonstates how to use Python Riva API.\n",
    "\n",
    "## Server\n",
    "\n",
    "Before running client part of Riva, please set up a server. The simplest\n",
    "way to do this is to follow\n",
    "[quick start guide](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html#local-deployment-using-quick-start-scripts).\n",
    "\n",
    "\n",
    "## Authentication\n",
    "\n",
    "Before using Riva services you will need to establish connection with a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import riva_api\n",
    "\n",
    "uri = \"localhost:50051\"  # Default value\n",
    "\n",
    "auth = riva_api.Auth(uri=uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5319eae",
   "metadata": {},
   "source": [
    "## ASR\n",
    "\n",
    "To instantiate a service pass `riva_api.Auth` instance to a constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_service = riva_api.ASRService(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f6a1c",
   "metadata": {},
   "source": [
    "For speech recognition you will need to create a recognition config (an instance of `riva_api.RecognitionConfig`). \n",
    "A detailed description of config fields is available in Riva \n",
    "[documentation](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/reference/protos/riva_asr.proto.html?highlight=max%20alternatives#riva-proto-riva-asr-proto).\n",
    "If you intend to use streaming recognition, an offline config has to wrapped into `riva_api.StreamingRecognitionConfig`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "offline_config = riva_api.RecognitionConfig(\n",
    "    encoding=riva_api.AudioEncoding.LINEAR_PCM,\n",
    "    max_alternatives=1,\n",
    "    enable_automatic_punctuation=True,\n",
    "    verbatim_transcripts=False,\n",
    ")\n",
    "streaming_config = riva_api.StreamingRecognitionConfig(config=deepcopy(offline_config), interim_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e975f38",
   "metadata": {},
   "source": [
    "You also need to a set frame rate and number of channels of audio which is going to be processed. If you'd like to process file `examples/en-US_AntiBERTa_for_word_boosting_testing.wav`, then your code will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3723b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_wav_file = 'examples/en-US_AntiBERTa_for_word_boosting_testing.wav'\n",
    "riva_api.add_audio_file_specs_to_config(offline_config, my_wav_file)\n",
    "riva_api.add_audio_file_specs_to_config(streaming_config, my_wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8175e1d",
   "metadata": {},
   "source": [
    "If you intent to use word boosting, then use convenience method `riva_api.add_word_boosting_to_config()` to add boosting parameters to config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aff022",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_lm_words = ['AntiBERTa', 'ABlooper']\n",
    "boosted_lm_score = 20.0\n",
    "riva_api.add_word_boosting_to_config(offline_config, boosted_lm_words, boosted_lm_score)\n",
    "riva_api.add_word_boosting_to_config(streaming_config, boosted_lm_words, boosted_lm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7818f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(offline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(streaming_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87b82b",
   "metadata": {},
   "source": [
    "## Offline\n",
    "\n",
    "To run offline speech recognition read data from a file and pass to a service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(my_wav_file, 'rb') as fh:\n",
    "    data = fh.read()\n",
    "\n",
    "response = asr_service.offline_recognize(data, offline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35834e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd9348",
   "metadata": {},
   "source": [
    "To extract a transcript you may use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76532974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(response.results[0].alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaead038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.results[0].alternatives[0].confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5254e8",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "To imitate audio streaming use `riva_api.AudioChunkFileIterator`. You can imitate realtime audio by providing a delay callback to the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7d7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wav_parameters = riva_api.get_wav_file_parameters(my_wav_file)\n",
    "# correponds to 1 second of audio\n",
    "chunk_size = wav_parameters['framerate']\n",
    "with riva_api.AudioChunkFileIterator(\n",
    "    my_wav_file, chunk_size, delay_callback=riva_api.sleep_audio_length,\n",
    ") as audio_chunk_iterator:\n",
    "    for i, chunk in enumerate(audio_chunk_iterator):\n",
    "        print(i, len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b146f07",
   "metadata": {},
   "source": [
    "Then audio chunks are passed to `ASRService.streaming_response_generator()` and response generator is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunk_iterator = riva_api.AudioChunkFileIterator(my_wav_file, 4800)\n",
    "response_generator = asr_service.streaming_response_generator(audio_chunk_iterator, streaming_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8ee10",
   "metadata": {},
   "source": [
    "You may find description of streaming response (`StreamingRecognizeResponse`) fields in Riva [documentation](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/reference/protos/riva_asr.proto.html?highlight=max%20alternatives#riva-proto-riva-asr-proto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f401240",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_response = next(response_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9df74c",
   "metadata": {},
   "source": [
    "For showing streaming results it is convenient to use function `riva_api.print_streaming()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "riva_api.print_streaming(response_generator, additional_info='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc7afb",
   "metadata": {},
   "source": [
    "If you set a delay callback in audio chunk iterator and `show_intermediate=True` in `riva_api.print_streaming()`, then you will be able watch transcript forming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunk_iterator = riva_api.AudioChunkFileIterator(my_wav_file, 4800, riva_api.sleep_audio_length)\n",
    "response_generator = asr_service.streaming_response_generator(audio_chunk_iterator, streaming_config)\n",
    "riva_api.print_streaming(response_generator, show_intermediate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
